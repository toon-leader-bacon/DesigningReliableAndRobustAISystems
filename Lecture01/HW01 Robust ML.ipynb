{"cells":[{"cell_type":"markdown","metadata":{"id":"dDzfiLFORA7v"},"source":["# Welcome to Homework #1: Robust ML!\n","In this homework assignment you will complete the following three tasks\n","1. Implement Empirical Risk Minimization\n","2. Implement GroupDRO Algorithm following the lecture. For more information you can look at the original paper:\n"," > [Sagawa, Shiori, et al. \"Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization.\" International Conference on Learning Representations (ICLR), 2020.](https://arxiv.org/abs/1911.08731)\n","3. Fine-tune a pre-trained vision transformer\n","4. Compare robustness properties of the three approaches\n","\n","\n","##IMPORTANT:\n","  > Before you get started, select `Runtime > Change runtime type` and select `GPU` for your hardware accelerator.\n","\n","\n","##A couple of notes\n","1. Make sure to run each cell in order!\n","2. Only fill in code in sections marked as follows:\n","```\n","# <<<<<< Put your code here\n","# Write your code\n","# >>>>>\n","```\n","\n","Let's get started!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kIfb_GoAlvGr"},"source":["## Environment Setup"]},{"cell_type":"markdown","metadata":{"id":"t7VeWYBDTCWZ"},"source":["First we have to install the `wilds` python package which will give us access to the Waterbirds dataset. Run the command and give it ~1 min to install."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":12840,"status":"ok","timestamp":1690223615849,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"ht-aSxaeO-VD"},"outputs":[],"source":["%%capture\n","!pip install wilds"]},{"cell_type":"markdown","metadata":{"id":"IkR-pJgYTS36"},"source":["Now we load each of the packages we need for the worksheet. See the comments for the purpose of each"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5030,"status":"ok","timestamp":1690223623433,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"Kel5_ptAtPE_"},"outputs":[],"source":["from wilds import get_dataset # Function to download wilds datasets\n","import torch # Pytorch library used for defining and training ML models\n","import torch.nn as nn # the nerual network library used for defining models\n","from torch.utils.data import DataLoader # Used for wrapping and iterating through out data\n","import torchvision # Package with utilities for computer vision such as pretrained models\n","import torchvision.transforms as transforms # Set of image transforms for processing image inputs\n","\n","import numpy as np # Numpy used for general array manipulation\n","import matplotlib.pyplot as plt # Used for showing images\n","import pandas as pd # Used for storing our results\n","\n","from tqdm import tqdm # Progress bar while training\n","import warnings # Give warnings, such as if CUDA is unavailable\n","import multiprocessing # Allows us to check the number of available CPUS"]},{"cell_type":"markdown","metadata":{"id":"oeD2W1OATctD"},"source":["Now we check that GPU-support is available. If not, you may have forgotten to select the GPU hardware accelerator. We also set some useful constants."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":403,"status":"ok","timestamp":1690223633228,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"KzS5nNW0Ta9T"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\bacon\\AppData\\Local\\Temp\\ipykernel_14184\\2453893812.py:2: UserWarning: CUDA is not available, please check that you have selected a GPU for hardware acceleration\n","  warnings.warn(\n"]}],"source":["if not torch.cuda.is_available():\n","    warnings.warn(\n","        \"CUDA is not available, please check that you have selected a GPU for hardware acceleration\"\n","    )\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","N_CORES = multiprocessing.cpu_count()"]},{"cell_type":"markdown","metadata":{"id":"YdrshdD5UhHJ"},"source":["## Download and visualize the dataset"]},{"cell_type":"markdown","metadata":{"id":"WYO-PE_N2pH2"},"source":["Next we will download and visualize the waterbirds dataset. The waterbirds dataset is a synthetic binary classification dataset where the goal is to predict if a bird is a \"Landbird\" or a \"Waterbird\". The birds have been placed on artificial backgrounds where roughly 95% of the time landbirds are against a land backdrop and waterbirds are against a water backdrop. The other 5% of the time landbirds are found over water and waterbirds are found on land. Each of the four confirgurations of \"Landbird vs. Waterbird\" and \"over land vs. over water\" makes up a subgroup. Let's begin!"]},{"cell_type":"markdown","metadata":{"id":"5tp_x4JeW9FK"},"source":["Run the command below to download the waterbirds (should take 1-5 minutes to download). If your session stays active you won't need to re-download this each time you run it."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70636,"status":"ok","timestamp":1690223708625,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"f-k2gjTGLaxf","outputId":"b104df2f-b831-4dec-bdb3-fdd3dd9c094b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading dataset to data\\waterbirds_v1.0...\n","You can also download the dataset manually at https://wilds.stanford.edu/downloads.\n","Downloading https://worksheets.codalab.org/rest/bundles/0x505056d5cdea4e4eaa0e242cbfe2daa4/contents/blob/ to data\\waterbirds_v1.0\\archive.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["0Byte [00:00, ?Byte/s]"]},{"name":"stdout","output_type":"stream","text":["Failed download. Trying https -> http instead. Downloading http://worksheets.codalab.org/rest/bundles/0x505056d5cdea4e4eaa0e242cbfe2daa4/contents/blob/ to data\\waterbirds_v1.0\\archive.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["0Byte [00:00, ?Byte/s]\n","0Byte [00:00, ?Byte/s]"]},{"name":"stdout","output_type":"stream","text":["\n","data\\waterbirds_v1.0\\archive.tar.gz may be corrupted. Please try deleting it and rerunning this command.\n","\n","Exception:  <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'data\\\\waterbirds_v1.0\\\\metadata.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\bacon\\Projects\\git\\DesigningReliableAndRobustAISystems\\Lecture01\\HW01 Robust ML.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bacon/Projects/git/DesigningReliableAndRobustAISystems/Lecture01/HW01%20Robust%20ML.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m get_dataset(dataset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwaterbirds\u001b[39;49m\u001b[39m\"\u001b[39;49m, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\wilds\\get_dataset.py:75\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(dataset, version, unlabeled, **dataset_kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39melif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwaterbirds\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mwilds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwaterbirds_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m WaterbirdsDataset\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m WaterbirdsDataset(version\u001b[39m=\u001b[39mversion, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39melif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39myelp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mwilds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39myelp_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m YelpDataset\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\wilds\\datasets\\waterbirds_dataset.py:72\u001b[0m, in \u001b[0;36mWaterbirdsDataset.__init__\u001b[1;34m(self, version, root_dir, download, split_scheme)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     68\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir\u001b[39m}\u001b[39;00m\u001b[39m does not exist yet. Please generate the dataset first.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[39m# Read in metadata\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m# Note: metadata_df is one-indexed.\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m metadata_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m     73\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_dir, \u001b[39m'\u001b[39;49m\u001b[39mmetadata.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     75\u001b[0m \u001b[39m# Get the y values\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_array \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(metadata_df[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues)\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\bacon\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\waterbirds_v1.0\\\\metadata.csv'"]}],"source":["dataset = get_dataset(dataset=\"waterbirds\", download=False)"]},{"cell_type":"markdown","metadata":{"id":"c-zmU48SUzTH"},"source":["Now lets visualize one training example from each subgroup (remember to read the section above explaining what the four subgroups are)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"executionInfo":{"elapsed":2720,"status":"ok","timestamp":1690223713336,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"KS4ccxzWjVTG","outputId":"0f05f448-8018-4490-dcd0-85864a1f5b7b"},"outputs":[{"ename":"NameError","evalue":"name 'dataset' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\bacon\\Projects\\git\\DesigningReliableAndRobustAISystems\\Lecture01\\HW01 Robust ML.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bacon/Projects/git/DesigningReliableAndRobustAISystems/Lecture01/HW01%20Robust%20ML.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Get the number of groups (should be 4)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bacon/Projects/git/DesigningReliableAndRobustAISystems/Lecture01/HW01%20Robust%20ML.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m n_groups \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39m_eval_grouper\u001b[39m.\u001b[39mn_groups\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bacon/Projects/git/DesigningReliableAndRobustAISystems/Lecture01/HW01%20Robust%20ML.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Get a list of all the group ids for each data point in the dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bacon/Projects/git/DesigningReliableAndRobustAISystems/Lecture01/HW01%20Robust%20ML.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m group_ids \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39m_eval_grouper\u001b[39m.\u001b[39mmetadata_to_group(dataset\u001b[39m.\u001b[39mmetadata_array)\n","\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"]}],"source":["# Get the number of groups (should be 4)\n","n_groups = dataset._eval_grouper.n_groups\n","\n","# Get a list of all the group ids for each data point in the dataset\n","group_ids = dataset._eval_grouper.metadata_to_group(dataset.metadata_array)\n","\n","# Define the group and class labels\n","group_labels = [\"Landbird on Land\", \"Landbird on Water\", \"Waterbird on Land\", \"Waterbird on Water\"]\n","class_labels = [\"Landbird\", \"Waterbird\"]\n","\n","# Sample one random image from each group\n","np.random.seed(2)\n","sample_images = [dataset[np.random.choice(np.where(group_ids == i)[0])][0] for i in range(n_groups)]\n","\n","# Plot the figures with the group label as the title\n","fig, axs = plt.subplots(1, n_groups, figsize=(3*n_groups, 3))\n","\n","for i in range(n_groups):\n","    axs[i].imshow(sample_images[i], extent=[0,1,0,1])\n","    axs[i].set_title(group_labels[i])\n","    axs[i].axis('off')\n","\n","plt.subplots_adjust(wspace=0.2)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Y3dpFrp6Waca"},"source":["## Create Train, Val, Test Splits\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JMR6uetLXCuE"},"source":["We can use the built-in utilities from the `wilds` package, but to do so, we need to define the set of transforms which involves resizing, cropping and then converting the image to a tensor and then normalizing it so the inputs are roughly in the range `[-1, 1]`"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1068,"status":"ok","timestamp":1690223730073,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"iis2jVtrQApO"},"outputs":[],"source":["# Define the set of transforms used in the original paper\n","data_transforms = transforms.Compose(\n","    [\n","        transforms.Resize((256, 256)),\n","        transforms.CenterCrop((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225],),\n","    ]\n",")\n","\n","# Built in subset utilities from \"wilds\"\n","train_data = dataset.get_subset(\"train\", transform=data_transforms)\n","val_data = dataset.get_subset(\"val\", transform=data_transforms)\n","test_data = dataset.get_subset(\"test\", transform=data_transforms)\n","\n","# Construct some noisy data (This is used in the later half of the homework)\n","noisy_transform = transforms.Compose([data_transforms, lambda tensor: tensor + torch.randn(tensor.size())])\n","noisy_val_data = dataset.get_subset(\"val\", transform=noisy_transform)"]},{"cell_type":"markdown","metadata":{"id":"A5tUuP5jYoGE"},"source":["Lets find out how many examples of each group are in our training sets"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":1050,"status":"ok","timestamp":1690223736400,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"FW9n4jX9QQ5s","outputId":"622bc035-1cdc-465f-db96-8cb1b99ebc80"},"outputs":[{"data":{"text/html":["\n","\n","  <div id=\"df-0edbe320-91d8-412e-ac2c-cce33fb96ba2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Landbird on Land</th>\n","      <th>Landbird on Water</th>\n","      <th>Waterbird on Land</th>\n","      <th>Waterbird on Water</th>\n","      <th>Total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Training Examples</th>\n","      <td>3498</td>\n","      <td>184</td>\n","      <td>56</td>\n","      <td>1057</td>\n","      <td>4795</td>\n","    </tr>\n","    <tr>\n","      <th>Val Examples</th>\n","      <td>467</td>\n","      <td>466</td>\n","      <td>133</td>\n","      <td>133</td>\n","      <td>1199</td>\n","    </tr>\n","    <tr>\n","      <th>Test Examples</th>\n","      <td>2255</td>\n","      <td>2255</td>\n","      <td>642</td>\n","      <td>642</td>\n","      <td>5794</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0edbe320-91d8-412e-ac2c-cce33fb96ba2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-022e7a8a-c2f5-42cd-a88f-4b45ed25b164\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-022e7a8a-c2f5-42cd-a88f-4b45ed25b164')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-022e7a8a-c2f5-42cd-a88f-4b45ed25b164 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0edbe320-91d8-412e-ac2c-cce33fb96ba2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0edbe320-91d8-412e-ac2c-cce33fb96ba2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"],"text/plain":["                   Landbird on Land  Landbird on Water  Waterbird on Land  \\\n","Training Examples              3498                184                 56   \n","Val Examples                    467                466                133   \n","Test Examples                  2255               2255                642   \n","\n","                   Waterbird on Water  Total  \n","Training Examples                1057   4795  \n","Val Examples                      133   1199  \n","Test Examples                     642   5794  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Get the group id for each of the examples in each split\n","train_groups = dataset._eval_grouper.metadata_to_group(train_data.metadata_array)\n","val_groups = dataset._eval_grouper.metadata_to_group(val_data.metadata_array)\n","test_groups = dataset._eval_grouper.metadata_to_group(test_data.metadata_array)\n","\n","# Count the number of examples of each group type\n","train_examples_per_group = [(train_groups == i).sum().item() for i in range(n_groups)]\n","val_examples_per_group = [(val_groups == i).sum().item() for i in range(n_groups)]\n","test_examples_per_group = [(test_groups == i).sum().item() for i in range(n_groups)]\n","\n","# Store the results in a data frame to display\n","data_summary = pd.DataFrame(columns=[*group_labels, \"Total\"])\n","data_summary.loc[0] = [*train_examples_per_group, sum(train_examples_per_group)]\n","data_summary.loc[1] = [*val_examples_per_group, sum(val_examples_per_group)]\n","data_summary.loc[2] = [*test_examples_per_group, sum(test_examples_per_group)]\n","data_summary.index = ['Training Examples', 'Val Examples', 'Test Examples']\n","data_summary"]},{"cell_type":"markdown","metadata":{"id":"ea47AOMaZmQP"},"source":["## Define our Model and the functions to evaluate it"]},{"cell_type":"markdown","metadata":{"id":"GlhqhIkcaFf6"},"source":["This function loads a `resnet50` model from torchivsion and replaces the final classification layer with a new layer of the appropriate size. The waterbirds classification class is binary (\"Landbird\" or \"waterbird\") so we use two outputs."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":394,"status":"ok","timestamp":1690223739738,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"6MRhP4lUUI8t"},"outputs":[],"source":["def Resnet50(outputs=2):\n","    # Load a resent50 model with the default pre-trained weights\n","    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n","\n","    # Replace the Feature Classifier (fc) with a new linear layer with 2 output dimensions\n","    d = model.fc.in_features\n","    model.fc = nn.Linear(d, outputs)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"BQuFhUf0ak2f"},"source":["This function computes the predictions of the model on the dataset. It returns the true labels, the predicted labels and the group id of each datapoint in the dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":333,"status":"ok","timestamp":1690223744565,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"Ncb1BlAcaQ3W"},"outputs":[],"source":["def get_predictions(model, dataset, batch_size=32):\n","    # Put the model on the target device\n","    model = model.to(DEVICE)\n","\n","    # Construct a dataloader with the specified batch size\n","    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=N_CORES)\n","\n","    # Empty arrays for storing labels and predictions and groups\n","    ypred = []\n","    y = []\n","    group = []\n","\n","    # Put the model in eval model and don't store gradients\n","    model.eval()\n","    with torch.no_grad():\n","        # Loop through all data in batches\n","        for inputs, labels, metadata in dataloader:\n","            groups = dataset.dataset._eval_grouper.metadata_to_group(metadata)\n","            inputs = inputs.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            # Compute model outputs and  predictions\n","            outputs = model(inputs)\n","            predicted = torch.argmax(outputs.data, 1)\n","\n","            # Store the results\n","            ypred.extend(predicted.cpu().numpy())\n","            y.extend(labels.cpu().numpy())\n","            group.extend(groups)\n","\n","    return np.array(y), np.array(ypred), np.array(group)"]},{"cell_type":"markdown","metadata":{"id":"7opDFkapfom9"},"source":["This function uses the previous function and computes the per-group performance of the model on the provided dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":496,"status":"ok","timestamp":1690223748239,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"CLc3GnLyfoSm"},"outputs":[],"source":["def evaluate(model, dataset, batch_size=32):\n","    # Get the predictions\n","    y, ypred, group = get_predictions(model, dataset, batch_size)\n","\n","    # Compute accuracy for each group\n","    accuracies = []\n","    for i in range(n_groups):\n","        group_indices = group == i\n","        group_y = y[group_indices]\n","        group_ypred = ypred[group_indices]\n","        accuracy = (group_y == group_ypred).mean()\n","        accuracies.append(accuracy)\n","\n","    # Add the aggregate accuracy\n","    accuracies.append((y == ypred).mean())\n","    return accuracies\n"]},{"cell_type":"markdown","metadata":{"id":"6I-CfqhGf8Id"},"source":["## Empirical Risk Minimization (ERM)\n","\n","---\n","This is where we will begin our implementation, starting with the basic formulation of statistical machine learning: Empirical Risk Minimization.\n"]},{"cell_type":"markdown","metadata":{"id":"kQNQBXROgAlm"},"source":["This function trains a model using empirical risk minimization on the provided dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1690223890011,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"jSyq9w5WtRIe"},"outputs":[],"source":["def train_ERM(\n","    model,\n","    dataset,\n","    batch_size=128,\n","    num_epochs=1,\n","    learning_rate=1e-3,\n","    weight_decay=1e-4,\n","):\n","    # Move the model to the device\n","    model = model.to(DEVICE)\n","\n","    # <<<<<< Put your code here\n","    # Define the criterion to be used in the loss function [1 line]\n","    # Hint: you can find a list of loss functions here: https://pytorch.org/docs/stable/nn.html#loss-functions.\n","    \n","    # Quadratic, Cross-Entropy, Weighted Cross-Entropy, etc.\n","    # I'll use CrossEntropy because it's a common loss function.\n","    loss_criterion_func = nn.CrossEntropyLoss()\n","\n","    # >>>>>\n","\n","    # Define the optimizer\n","    optimizer = torch.optim.SGD(\n","        model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay\n","    )\n","\n","    # Construct the DataLoader\n","    dataloader = DataLoader(\n","        dataset, batch_size=batch_size, shuffle=True, num_workers=N_CORES\n","    )\n","\n","    # Construct the progess bar\n","    num_batches = len(dataloader)\n","    progress_bar = tqdm(\n","        total=num_batches * num_epochs, desc=\"Training Progress\", position=0, leave=True\n","    )\n","\n","\n","    # Put the model into train mode\n","    model.train()\n","\n","    # Loop over epochs\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","\n","        # Loop over data\n","        for (i, (inputs, labels, _)) in enumerate(dataloader):\n","            inputs = inputs.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            # <<<<<< Put your code here\n","            # Zero the gradients in the optimizezr [1 line]\n","            optimizer.zero_grad()\n","\n","            # Compute the model outputs [1 line]\n","            outputs = model(inputs)\n","\n","            # compute the loss according the criterion [1 line)\n","            # NOTE: Please keep this variable named \"loss\" as it is used later on to keep track of the running loss\n","            # NOTE: criterion is cross entropy loss function\n","            loss = loss_criterion_func(outputs, labels)\n","\n","            # Compute gradients of the loss and step the optimizer [2 lines]\n","            loss.backward() \n","            optimizer.step() # https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n","            # >>>>>\n","\n","            # Accumulate the running loss and update the progress bar\n","            running_loss += loss.item()\n","            progress_bar.update(1)\n","            progress_bar.set_postfix({'Epoch': epoch+1, 'Batch': i+1, 'Train_Loss': running_loss / (i+1)})\n","\n","    progress_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"ph1sNTRYjWFr"},"source":["Let's train our first model!\n","This should take about 1 min"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60306,"status":"ok","timestamp":1690223954404,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"uzgACrpNvxAA","outputId":"cbd3f525-1a93-4da7-9b45-4540f04cdc01"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:01<00:00, 92.4MB/s]\n","Training Progress: 100%|██████████| 38/38 [00:54<00:00,  1.43s/it, Epoch=1, Batch=38, Train_Loss=0.469]\n"]}],"source":["ERM_resnet = Resnet50()\n","train_ERM(ERM_resnet, train_data)"]},{"cell_type":"markdown","metadata":{"id":"ZnSvy5rnjc61"},"source":["Now that we have trained our model, let's evaluate it on the validation set to see how well we did"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17271,"status":"ok","timestamp":1690223985582,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"ph6PdUuF16-7"},"outputs":[],"source":["ERM_resnet_val_accuracies = evaluate(ERM_resnet, val_data)\n","ERM_resnet_noisy_val_accuracies = evaluate(ERM_resnet, noisy_val_data) # For later"]},{"cell_type":"markdown","metadata":{"id":"VjzcvcLepl_s"},"source":["Store the results in a table that we will re-use"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690223987309,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"m9QnTUOY6uwd","outputId":"d448650d-9675-4173-e8dd-cbcdd56be73d"},"outputs":[{"data":{"text/html":["\n","\n","  <div id=\"df-294753ac-cd9c-41ca-aa93-fa244de0e47e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Landbird on Land</th>\n","      <th>Landbird on Water</th>\n","      <th>Waterbird on Land</th>\n","      <th>Waterbird on Water</th>\n","      <th>Aggregate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ERM - ResNet - Val</th>\n","      <td>1.0</td>\n","      <td>0.856223</td>\n","      <td>0.045113</td>\n","      <td>0.578947</td>\n","      <td>0.791493</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-294753ac-cd9c-41ca-aa93-fa244de0e47e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-0730454f-2ba5-4697-a7b8-9580160eb4d3\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0730454f-2ba5-4697-a7b8-9580160eb4d3')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-0730454f-2ba5-4697-a7b8-9580160eb4d3 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-294753ac-cd9c-41ca-aa93-fa244de0e47e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-294753ac-cd9c-41ca-aa93-fa244de0e47e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"],"text/plain":["                    Landbird on Land  Landbird on Water  Waterbird on Land  \\\n","ERM - ResNet - Val               1.0           0.856223           0.045113   \n","\n","                    Waterbird on Water  Aggregate  \n","ERM - ResNet - Val            0.578947   0.791493  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["results = pd.DataFrame(columns=[*group_labels, \"Aggregate\"])\n","results.loc[0] = ERM_resnet_val_accuracies\n","results.rename(index={0: 'ERM - ResNet - Val'}, inplace=True)\n","results"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1690223999954,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"JK2bvcifHu-j"},"outputs":[],"source":["torch.save(ERM_resnet, \"ERM_resnet.ckpt\")\n"]},{"cell_type":"markdown","metadata":{"id":"wq5u8BphuJsS"},"source":["Clear the GPU memory so we can train a new model next"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"elapsed":1017,"status":"error","timestamp":1690225037042,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"1BueqzJmt2cx","outputId":"f75d3000-c3fc-4c53-8815-807ba87ca1c4"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-ef936c8d1a62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mERM_resnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ERM_resnet' is not defined"]}],"source":["del ERM_resnet\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"Sbilm3sGlWSo"},"source":["## Group Distributionally Robust Optimization (GroupDRO)"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1690225048976,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"ZVGA_4MuNwzS"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1690225052399,"user":{"displayName":"xacer c","userId":"02453598874398586068"},"user_tz":240},"id":"5tUV5laG7FD-"},"outputs":[],"source":["def train_GroupDRO(\n","    model,\n","    dataset,\n","    batch_size=128,\n","    num_epochs=1,\n","    learning_rate=1e-3,\n","    weight_decay=1e-4,\n","    step_size=0.01 # This is \\eta_q from the slides\n","):\n","    # Move the model to the device\n","    model = model.to(DEVICE)\n","\n","    # <<<<<< Put your code here\n","    # Define the criterion to be used in the loss function [1 line]\n","    # Using the same cross entropy loss function as the one chosen above\n","    loss_criterion_func = nn.CrossEntropyLoss()\n","    # >>>>>\n","\n","    # Define the optimizer\n","    optimizer = torch.optim.SGD(\n","        model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay\n","    )\n","\n","    # Construct the DataLoader\n","    dataloader = DataLoader(\n","        dataset, batch_size=batch_size, shuffle=True, num_workers=N_CORES\n","    )\n","\n","    # Construct the progress bar\n","    num_batches = len(dataloader)\n","    progress_bar = tqdm(\n","        total=num_batches * num_epochs, desc=\"Training Progress\", position=0, leave=True\n","    )\n","\n","\n","    # Put the model into train mode\n","    model.train()\n","\n","    # <<<<<< Put your code here\n","    # Initialize group weights to all ones [1 line]\n","    # Hint: to get the number of groups use the variable \"n_groups\" which we defined when we loaded in the dataset.\n","    \n","    # Create a tensor of dimension n_groups x 1 long, each element is value 1\n","    group_weights = torch.ones(n_groups)\n","    # >>>>>\n","\n","    # Loop over epochs\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","\n","        # Loop over data\n","        for (i, (inputs, labels, metadata)) in enumerate(dataloader):\n","            inputs = inputs.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","            groups = dataset.dataset._eval_grouper.metadata_to_group(metadata) # (batch_size,)\n","\n","            # <<<<<< Put your code here\n","            # Zero the gradients in the optimizer [1 line]\n","            optimizer.zero_grad()\n","            \n","            # Compute the model outputs [1 line]\n","            # NOTE: Outputs has 2 output dimensions\n","            outputs = model(inputs)\n","            \n","            # Calculate per-group losses [~5 lines]\n","            # Hint: Iterate over the group ids and compute the loss for all inputs that match the group. The \"groups\" variable defined above may be helpful.\n","            losses_by_group = torch.zeros(n_groups)\n","            for output_element_index, group_label in enumerate(groups):\n","                # NOTE: group_label is a number in range [0, 3]\n","                output_at_index = outputs[output_element_index][None]\n","                label_at_index = outputs[output_element_index][None]\n","                losses_by_group[group_label] = loss_criterion_func(output_at_index, label_at_index)\n","\n","            # Update the group weights and normalize them [2 lines]\n","            # Hint: The variable step_size provided as input to the function is the same as \\eta_q in the slides. Use it here.\n","            # NOTE: group_weights are initialized to tensor of all 1s\n","            group_weights = group_weights * (losses_by_group.exp(step_size))\n","            group_weights = group_weights / group_weights.sum()\n","            # group_weights = group_weights * group_losses.exp() * step_size\n","            # group_weights = group_weights / group_weights.sum()\n","\n","            # Compute the weighted average of per-group losses [1 line]\n","            # NOTE: Please keep this variable named \"weighted_loss\" as it is used later on to keep track of the running loss\n","            weighted_loss = group_weights * losses_by_group\n","            weighted_loss = weighted_loss - (group_weights * losses_by_group)\n","\n","            # Compute gradients of the loss and step the optimizer [2 lines]\n","            weighted_loss.backward()\n","            optimizer.step()\n","            # >>>>>\n","\n","            # Accumulate the running loss and update the progress bar\n","            running_loss += weighted_loss.item()\n","            progress_bar.update(1)\n","            progress_bar.set_postfix({'Epoch': epoch+1, 'Batch': i+1, 'Train_Loss': running_loss / (i+1)})\n","\n","    progress_bar.close()"]},{"cell_type":"markdown","metadata":{"id":"obe1CWeXyMBg"},"source":["Train the GroupDRO ResNet50 Model (~1 min)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pf-q8PuVmUBs","outputId":"54c841e0-3bfa-4433-907c-2dd6dfdb2739"},"outputs":[{"name":"stderr","output_type":"stream","text":["\rTraining Progress:   0%|          | 0/38 [00:00<?, ?it/s]"]}],"source":["GroupDRO_resnet = Resnet50()\n","DEVICE=torch.device(\"cpu\")\n","train_GroupDRO(GroupDRO_resnet, train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yjIxMijrELIK"},"outputs":[],"source":["from google.colab import files\n","torch.save(GroupDRO_resnet, \"GroupDRO_resnet.ckpt\")\n","files.download( \"GroupDRO_resnet.ckpt\" )"]},{"cell_type":"markdown","metadata":{"id":"4QH5klUxyG_a"},"source":["Evaluate the GroupDRO model on the validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulGpBlmVph_t"},"outputs":[],"source":["GroupDRO_resnet_val_accuracies = evaluate(GroupDRO_resnet, val_data)\n","GroupDRO_resnet_noisy_val_accuracies = evaluate(GroupDRO_resnet, noisy_val_data) # For later"]},{"cell_type":"markdown","metadata":{"id":"04i1SLJjyD0d"},"source":["Store the results in our table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbegWwsnw3_Z"},"outputs":[],"source":["results.loc[1] = GroupDRO_resnet_val_accuracies\n","results.rename(index={1: 'GroupDRO - ResNet - Val'}, inplace=True)\n","results"]},{"cell_type":"markdown","metadata":{"id":"KGqAwxM30veO"},"source":["How does GroupDRO compare to ERM?"]},{"cell_type":"markdown","metadata":{"id":"Ky9M6aYUx8kc"},"source":["Clear the GPU memory so we can train a new model next"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dH6A9QhwwuDx"},"outputs":[],"source":["del GroupDRO_resnet\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"MPQOWe5jyS8t"},"source":["## Fine-Tuning a Vision Transformer"]},{"cell_type":"markdown","metadata":{"id":"ZK1b8Rz1zFTa"},"source":["This function will return a Vision Transformer that is ready to be fine-tuned. It should be intitialized with the default set of weights.\n","\n","To enable fine-tuning we will freeze all but the final layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChTFQbrryV_A"},"outputs":[],"source":["def ViT(output=2):\n","    # <<<<<< Put your code here\n","    # Load vit_b_16 torchvision model with weights=torchvision.models.ViT_B_16_Weights.DEFAULT\n","\n","    # Disable all of the gradients for all parameters [2 lines]\n","\n","    # Replace the last \"head\" with a new linear layer of the appropriate size [~2 lines]\n","    # HINT: The last layer is in list called \"heads\".\n","    # HINT: Refer to the ResNet50() function above to see how to make a new layer\n","\n","    # >>>>>\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"JzvxxHpyzXXn"},"source":["Train a ViT using ERM and evaluate (~2-3 min)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi5hNdqFzWzf"},"outputs":[],"source":["ERM_vit = ViT()\n","train_ERM(ERM_vit, train_data)\n","ERM_vit_val_accuracies = evaluate(ERM_vit, val_data)\n","ERM_vit_noisy_val_accuracies = evaluate(ERM_vit, noisy_val_data)\n","del ERM_vit\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"KgzqsjsLza9o"},"source":["Train a ViT using GroupDRO and evaluate  (~2-3 min)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c57z-0rA0JYU"},"outputs":[],"source":["GroupDRO_vit = ViT()\n","train_GroupDRO(GroupDRO_vit, train_data)\n","GroupDRO_vit_val_accuracies = evaluate(GroupDRO_vit, val_data)\n","GroupDRO_vit_noisy_val_accuracies = evaluate(GroupDRO_vit, noisy_val_data)\n","del GroupDRO_vit\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60Y_gPC_0PWb"},"outputs":[],"source":["results.loc[2] = ERM_vit_val_accuracies\n","results.loc[3] = GroupDRO_vit_val_accuracies\n","results.rename(index={2: 'ERM - ViT - Val'}, inplace=True)\n","results.rename(index={3: 'GroupDRO - ViT - Val'}, inplace=True)\n","results"]},{"cell_type":"markdown","metadata":{"id":"DD4R3UYz1j0A"},"source":["## Robustness to Noise"]},{"cell_type":"markdown","metadata":{"id":"tqwAFAM61sfw"},"source":["In addition to evaluating on the validation set, we created a \"noisy\" validation set that included Gaussian noise on the inputs.\n","\n","An example of Gaussian noise is below\n","![](https://www.researchgate.net/publication/221913964/figure/fig7/AS:305170975084549@1449769838319/Examples-of-images-modified-by-Gaussian-noise-Gaussian-noise-was-applied-on-each-image.png)\n","\n","In general, a model's performance will drop due to this perturbation, but a robust model will retain its performance better. Let's see how the different model architecture compare"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nngm3gDV1Sdd"},"outputs":[],"source":["noisy_results = pd.DataFrame(columns=[\"Clean Accuracy\", \"Noisy Accuracy\"])\n","noisy_results.loc[0] = [GroupDRO_resnet_val_accuracies[-1], GroupDRO_resnet_noisy_val_accuracies[-1]]\n","noisy_results.loc[1] = [GroupDRO_vit_val_accuracies[-1], GroupDRO_vit_noisy_val_accuracies[-1]]\n","noisy_results.rename(index={0: 'DRO - ResNet'}, inplace=True)\n","noisy_results.rename(index={1: 'DRO - ViT'}, inplace=True)\n","noisy_results"]},{"cell_type":"markdown","metadata":{"id":"MoTPjfjz6BjT"},"source":["Does the pre-trained ViT improve robustness to noise?"]},{"cell_type":"markdown","metadata":{"id":"PWwWymUs5_Dj"},"source":["## Conclusion and Bonus Activities\n","\n","\n","---\n","\n","\n","\n","Congratulations on completing the assignment! You can stop here, or if you want to try out some additional concepts from lecture consider trying one of the following\n","\n","\n","1. Experiment with other architectures and pre-training types. You can find a list of pre-trained models [here](https://pytorch.org/vision/stable/models.html)\n","2. Experiment with robustness to other types of transformations, or try augmentating your training data with them. Available transforms in torchvision are [here](https://pytorch.org/vision/main/transforms.html)\n","3. Implement DeepCORAL [paper](https://arxiv.org/abs/1607.01719), [sample code](https://github.com/DenisDsh/PyTorch-Deep-CORAL)   \n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
